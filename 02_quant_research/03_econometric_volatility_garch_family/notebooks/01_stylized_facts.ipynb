{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stylized Facts of Financial Returns\n",
    "\n",
    "This notebook analyzes empirical properties of financial returns that motivate volatility modeling:\n",
    "\n",
    "1. **Fat tails**: Returns exhibit excess kurtosis\n",
    "2. **Volatility clustering**: Large moves tend to cluster\n",
    "3. **Leverage effect**: Negative shocks increase volatility more\n",
    "4. **No autocorrelation in returns**: Weak form efficiency\n",
    "5. **Strong autocorrelation in |returns| and returns²**: Volatility persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.returns import StylizedFacts\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "returns, prices = loader.prepare_dataset(\n",
    "    ticker=\"^GSPC\",\n",
    "    start_date=\"2010-01-01\",\n",
    "    return_method=\"log\"\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(returns)} daily returns\")\n",
    "print(f\"Date range: {returns.index[0]} to {returns.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StylizedFacts(returns)\n",
    "summary = sf.summary_statistics()\n",
    "\n",
    "summary_df = pd.DataFrame(summary, index=[0]).T\n",
    "summary_df.columns = ['Value']\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Mean ≈ 0: No predictable drift at daily frequency\n",
    "- Excess kurtosis > 0: Fat tails (leptokurtic distribution)\n",
    "- Negative skewness: Left tail is heavier (crash risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(returns, bins=100, density=True, alpha=0.7, edgecolor='black')\n",
    "x_range = np.linspace(returns.min(), returns.max(), 100)\n",
    "axes[0].plot(x_range, stats.norm.pdf(x_range, returns.mean(), returns.std()), \n",
    "             'r-', linewidth=2, label='Normal')\n",
    "axes[0].set_title('Return Distribution vs Normal')\n",
    "axes[0].set_xlabel('Log Returns')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(returns, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot vs Normal')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_tests = sf.normality_tests()\n",
    "\n",
    "print(\"Normality Tests:\")\n",
    "for test_name, (stat, pval) in normality_tests.items():\n",
    "    print(f\"  {test_name:20s}: stat={stat:10.2f}, p-value={pval:.6f}\")\n",
    "    if pval < 0.05:\n",
    "        print(f\"    → Reject normality at 5% level\")\n",
    "    else:\n",
    "        print(f\"    → Cannot reject normality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_df = sf.autocorrelation_structure(max_lag=30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(acf_df['lag'], acf_df['acf_returns'], 'o-', label='Returns', markersize=4)\n",
    "ax.plot(acf_df['lag'], acf_df['acf_abs_returns'], 's-', label='|Returns|', markersize=4)\n",
    "ax.plot(acf_df['lag'], acf_df['acf_squared_returns'], '^-', label='Returns²', markersize=4)\n",
    "\n",
    "# Confidence bands\n",
    "n = len(returns)\n",
    "conf_level = 1.96 / np.sqrt(n)\n",
    "ax.axhline(conf_level, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.axhline(-conf_level, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Autocorrelation Function', fontsize=12)\n",
    "ax.set_xlabel('Lag')\n",
    "ax.set_ylabel('Autocorrelation')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Finding:** Returns show little autocorrelation, but |returns| and returns² show strong persistence. This is the signature of **volatility clustering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCH Effects Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ljung-Box tests\n",
    "lb_returns = sf.ljung_box_test(lags=10, series_type='returns')\n",
    "lb_squared = sf.ljung_box_test(lags=10, series_type='squared')\n",
    "\n",
    "print(\"Ljung-Box Test (10 lags):\")\n",
    "print(f\"  Returns:  stat={lb_returns[0]:.2f}, p-value={lb_returns[1]:.6f}\")\n",
    "print(f\"  Squared:  stat={lb_squared[0]:.2f}, p-value={lb_squared[1]:.6f}\")\n",
    "\n",
    "# ARCH-LM test\n",
    "arch_lm = sf.arch_lm_test(lags=5)\n",
    "print(f\"\\nARCH-LM Test (5 lags):\")\n",
    "print(f\"  stat={arch_lm[0]:.2f}, p-value={arch_lm[1]:.6f}\")\n",
    "\n",
    "if arch_lm[1] < 0.05:\n",
    "    print(\"  → Strong evidence of ARCH effects (time-varying volatility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_corr = sf.leverage_effect_correlation(lag=1)\n",
    "\n",
    "print(f\"Leverage Effect (correlation between r_t and r²_{{t+1}}): {leverage_corr:.4f}\")\n",
    "\n",
    "if leverage_corr < 0:\n",
    "    print(\"  → Negative correlation confirms leverage effect\")\n",
    "    print(\"  → Negative shocks increase future volatility more than positive shocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tail Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_indices = sf.tail_index_estimation(tail_fraction=0.05)\n",
    "\n",
    "print(\"Tail Index Estimation (Hill estimator):\")\n",
    "print(f\"  Left tail (losses):  α = {tail_indices['left_tail_index']:.2f}\")\n",
    "print(f\"  Right tail (gains):  α = {tail_indices['right_tail_index']:.2f}\")\n",
    "print(\"\\n  Lower α = fatter tails\")\n",
    "print(\"  Normal distribution has α = ∞\")\n",
    "print(\"  Typical for financial returns: α ≈ 3-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility Clustering Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Returns over time\n",
    "plot_returns = returns.iloc[-1000:]\n",
    "axes[0].plot(plot_returns.index, plot_returns.values, linewidth=0.5, alpha=0.7)\n",
    "axes[0].set_title('Daily Returns (Last 1000 days)', fontsize=12)\n",
    "axes[0].set_ylabel('Log Returns')\n",
    "axes[0].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Absolute returns (volatility proxy)\n",
    "axes[1].plot(plot_returns.index, np.abs(plot_returns.values), linewidth=0.8, alpha=0.7)\n",
    "axes[1].set_title('Absolute Returns (Volatility Proxy)', fontsize=12)\n",
    "axes[1].set_ylabel('|Returns|')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Stylized facts confirmed:**\n",
    "\n",
    "1. ✓ Fat tails (excess kurtosis, non-normal distribution)\n",
    "2. ✓ Volatility clustering (strong ACF in squared returns)\n",
    "3. ✓ Leverage effect (negative correlation with future volatility)\n",
    "4. ✓ No return autocorrelation (weak form efficiency)\n",
    "5. ✓ ARCH effects present (time-varying volatility)\n",
    "\n",
    "**Implications:**\n",
    "- Constant volatility assumption is violated\n",
    "- Need conditional heteroskedasticity models (GARCH family)\n",
    "- Asymmetric models (EGARCH, GJR-GARCH) may capture leverage effect\n",
    "- Risk models must account for fat tails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
